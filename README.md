# multi-layer-perceptron-algorithm-implementation-in-python
Implementation of multi-layer perceptron and back propagation

- Implementing Multi-layer perceptron and back propagation to classify wine based on the quality.
- The MLP consists of one input layer with 13 neurons, a hidden layer with 64 neurons and a output layer with one neuron.
- The training is done till the loss is 0.01 and the learning rate for training is 0.01
